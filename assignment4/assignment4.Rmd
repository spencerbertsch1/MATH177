---
title: "Assignment 4 - QBS 177"
output: html_notebook
---

Spencer Bertsch  
Jan. 2022

------------

Some helpful commands:  
* Insert a new code chunk: *Cmd+Option+I*  
* Run a code cell: *Cmd+Shift+Enter*  
* Preview the notebook HTML file: *Cmd+Shift+K*  





### Imports 
```{r}
library(glue)
library(qqman)
```

First we need to change our current working directory to the correct directory for Assignment 3
```{r}
setwd('/Users/spencerbertsch/Desktop/dev/phd_courses/MATH177/assignment4')
getwd()
```

### Import the raw data 
```{r}
load('lab1.Rdata')
```


Here we can transform the subpopulation data into 21 countries instead of 25. We need this to be the case later on 
```{r}
chn <- (fulldat[,5] + fulldat[,6])/2
ind <- (fulldat[,11] + fulldat[,14])/2
nga <- (fulldat[,25] + fulldat[,8])/2
usa <- (0.777*fulldat[,4] + 0.132*fulldat[,2] + 0.053*(chn + ind + fulldat[,16] + fulldat[,15])/4)/(0.777+0.132+0.053)
fulldat <-fulldat[,c(3,1,5,7,9,12,11,24,15,17,19,25,21,20,22,18,13,23,10,4,16)]
fulldat[,3] <- chn
fulldat[,7] <- ind
fulldat[,12] <- nga
fulldat[,20] <- usa
```

The fulldat dataframe now has only 21 columns. 

We can now read in our response variable: the smoking data set
```{r}
yy <- read.delim("smoking_outcome.txt")
```




```{r}
y <- yy[,2]

# here we want to calculate the correlation between yy and the first 10000 loci
# we also want to know the p-values for each of the linear regressions run
plong <- corlong <- NULL

proc.time()
for (i in 1:10000){
  
  # remove loci with all minor allele frequncy 0
  if(var(fulldat[i,])){
    
  # run a linear regression using the smoking data as the response and the i'th row of fulldat as the predictor
  fit <- lm(y~fulldat[i,]) 
  
  # find the correlation between the response variable and the i'th row of fulldat
  # (This is why they needed to be of the same dimension! 21 elements long)
  corlong[i] <- cor(fulldat[i,], y)
  
  #output slope from linear regression
  plong[i] <- summary(fit)$coef[2,4] 
  }
}
proc.time()
```

This process took 2.54 seconds to finish, so if we assume that processing 10,000 records takes 2.54 seconds, then processing 1,099,146 samples would take 279.18 seconds, or about **4.65 minutes**. 

\n
We can now try to rewrite the above code without using a for loop so that we can improve the runtime of the algorithm. 
```{r}
# n is the sample size
n <- dim(yy)[1]  

# initialize a variable to store p values.
pvalue <- matrix(0, length(chr), 1) 

# initialize a variable to store correlation.
corvalue <- matrix(0, length(chr), 1) 

colnames(pvalue) <- c("prevave") 
colnames(corvalue) <- c("prevave")
```


And we can now run the vector operation to obtain the same information, but without using a for-loop. Let's see how much more quickly this process runs compared with the above process. 
```{r}
proc.time()
temp <- scale(t(fulldat))
y1 <- y/sqrt(var(y))

asd <- y1%*%temp/(n-1) # obtain correlation using apply 
#asd <- suppressWarnings(apply( t(fulldat) , 2 , cor , y)) # alternative way

# mid step to calculate p value
asd1 <- 1-asd^2  

# this is the T statistics
asd2 <- sqrt(n-2)*asd/sqrt(asd1) 

# transform T statistics to p-value
pvalue[,1] <- 2*(1-pt(abs(asd2),(n-2))) 

# pass correlation to corvalue.
corvalue[,1] <- asd 
proc.time()
```

Only 3.351 seconds instead of an estimated 4.65 minutes! Pretty great. We want to double check that we got the same correlations and p-values using the same two methods: 

```{r}
abs(sum(plong-pvalue[1:10000], na.rm=T))
abs(sum(corlong-corvalue[1:10000], na.rm=T))
```

And indeed we see that these two values are essentially zero, meaning that we were able to obtain the same correlations and p-values. 


\n 
We now want to generate a manhattan plot so we can visualize our data. In order to do this, we need to have a dataframe that has 4 columns with the following names: 
1. CHR
2. BP
3. SNP
4. P
These columns allows the plotting function to create the manhattan plot. 
In order to make our Manhattan plot below, we need to create a data frame with the charactersitics mentioned above: 
```{r}
# create dataframe with thefollwong chracteristics 
df1 <- data.frame(chr, pvalue, location)
```


We can use the below code to fill the NA values in the p-value vector in order to fix the bug in the plot 
```{r}
# pvalue[is.na(pvalue[,1]), 1] <- mean(pvalue[,1], na.rm = TRUE)
# sum(is.na(pvalue))
```
```{r}
# mu_new = colMeans(pvalue)
# print(mu_new)
# df1 <- data.frame(chr, pvalue, location)
```

Another option here instead of filling the p-values with the mean p-value is to simply drop the rows that have NAs in the position of p-values. It's probably not a best practice to fill NAs for the results of statistical tests, so better to throw out the records that are missing the results so we can ignore them. 
```{r}
print('We can find out how many NAs there are in our p-values:')
dim(df1)[1] - dim(df1[!is.na(df1$prevave),])[1]
df2 <- df1[!is.na(df1$prevave),]
```



## Question 1
Create a manhattan chart showing the resulting p-values and the 'chr' vector, and the 'locaiton' vector presented in the lab1.RData file: 
```{r}
# Make the Manhattan plot on the gwasResults dataset
manhattan(df2, chr="chr", bp="location", p="prevave", snp="location", col = c("gray10", "gray60"))
```

## Question 2
Identify top 9 locations on chromosome 21 based on the association p-values.

\n 
In order to answer this question we can take our newly created dataframe **df1** and sort it by p-value. Then we can take the top 9 rows and store the locations of those rows and use them to perform the online lookups to find the 'rs' number for the top 9 locations. 

```{r}
top_p_value_df <- df1[order(df1$prevave, decreasing=TRUE), ]
top_p_value_df
```

This is the result of looking up each of the top 9 p-values on https://www.ncbi.nlm.nih.gov

| Chromosome | p-value   | location | rs-number   |
|------------|-----------|----------|-------------|
| 21         | 0.9999864 | 27207117 | rs1580939   |
| 21         | 0.9999827 | 28712646 | rs9974655   |
| 21         | 0.9999793 | 44391110 | rs543093292 |
| 21         | 0.9999768 | 28892099 | rs28892099  |
| 21         | 0.9999670 | 21877114 | rs2212669   |
| 21         | 0.9999581 | 9499277  | rs561023278 |
| 21         | 0.9999581 | 16963839 | rs562942653 |
| 21         | 0.9999581 | 18461881 | rs557466620 |
| 21         | 0.9999581 | 23814186 | rs184788684 |

I note here that after the first 5 largest p-values, the next largest p-value has several repeated values. This means that, with no other relatively unique column to sort on, these values with constant p-value are unordered. It's then likely that the 4 rows in which the p-value is 0.9999581 might be different than rows for other students. Should I group the data frame by p-value and repeat this procedure, taking for example the max index number in each group? Then I would get only a single location for each p-value. 


## Question 3
Draw scatter plot between smoking prevalence (y) and minor allele frequencies of each lociâ€™s in 2. Add a regression line to the scatter plot. Add the correlation value to the plots as a legend. 

Use par(mfrow=c(3,3)) to plot all 9 figures in one plot

```{r}
# we have the response variable y:
yy
```

Now we need to get the minor allele frequencies for each of the top 9 records seen in question 2. **How do index the correct minor allele frequencies out of the fulldat matrix?** We only have the location... how do we find the correct row in fulldat using that information? We could save the highest p-values into an array and re-run the loop that runs all the regressions and perform a check. If we run into a p-value in the array then we save the index of the row and the row values so we can use them later on in Question 3. I feel like that's not the best way to go about it... 

```{r}
top_p_value_df
```


```{r}
# visualize loci 5 in fulldat
fulldat[5,]
```


Although we don't know the loci that correspond to the correct locations seens in question 2, we can still write the plotting code. 

Let's assume that the correct loci are: 2, 3, 4, 5, 6, 7, 8, 9, 10
```{r}
# we can prepare our data here: 
response <- yy[, 2]

maf_loci1 <- fulldat[2,]
maf_loci2 <- fulldat[3,]
maf_loci3 <- fulldat[4,]
maf_loci4 <- fulldat[4,]
maf_loci5 <- fulldat[5,]
maf_loci6 <- fulldat[6,]
maf_loci7 <- fulldat[7,]
maf_loci8 <- fulldat[8,]
maf_loci9 <- fulldat[9,]
```


Now that we have our predictors and response variables defined, we can create the matrix of scatter plots: 
```{r}
par(mfrow = c(3, 3))  

# 1st plot
plot(maf_loci1, response, pch=16, col='red', cex=1.2, main='First plot')                        
abline(lm(response ~ maf_loci1), col='blue')
c1 <- round(cor(maf_loci1, response, method = "pearson"), 3)
legend(0.009, 25, legend=c(c1), 
       fill = c("blue","red")
)

# 2nd plot
plot(maf_loci2, response, pch=16, col='red', cex=1.2, main='Second plot')                        
abline(lm(response ~ maf_loci2), col='blue')
c1 <- round(cor(maf_loci2, response, method = "pearson"), 3)
legend(0.009, 25, legend=c(c1), 
       fill = c("blue","red")
)

# 3rd plot
plot(maf_loci3, response, pch=16, col='red', cex=1.2, main='Third plot')                        
abline(lm(response ~ maf_loci3), col='blue')
c1 <- round(cor(maf_loci3, response, method = "pearson"), 3)
legend(0.009, 25, legend=c(c1), 
       fill = c("blue","red")
)

# 4th plot
plot(maf_loci4, response, pch=16, col='red', cex=1.2, main='Fourth plot')                        
abline(lm(response ~ maf_loci4), col='blue')
c1 <- round(cor(maf_loci4, response, method = "pearson"), 3)
legend(0.009, 25, legend=c(c1), 
       fill = c("blue","red")
)

# 5th plot
plot(maf_loci5, response, pch=16, col='red', cex=1.2, main='Fifth plot')                        
abline(lm(response ~ maf_loci5), col='blue')
c1 <- round(cor(maf_loci5, response, method = "pearson"), 3)
legend(0.009, 25, legend=c(c1), 
       fill = c("blue","red")
)

# 6th plot
plot(maf_loci6, response, pch=16, col='red', cex=1.2, main='Sixth plot')                        
abline(lm(response ~ maf_loci6), col='blue')
c1 <- round(cor(maf_loci6, response, method = "pearson"), 3)
legend(0.009, 25, legend=c(c1), 
       fill = c("blue","red")
)

# 7th plot
plot(maf_loci7, response, pch=16, col='red', cex=1.2, main='Seventh plot')                        
abline(lm(response ~ maf_loci7), col='blue')
c1 <- round(cor(maf_loci7, response, method = "pearson"), 3)
legend(0.009, 25, legend=c(c1), 
       fill = c("blue","red")
)

# 8th plot
plot(maf_loci8, response, pch=16, col='red', cex=1.2, main='Eighth plot')                        
abline(lm(response ~ maf_loci8), col='blue')
c1 <- round(cor(maf_loci8, response, method = "pearson"), 3)
legend(0.009, 25, legend=c(c1), 
       fill = c("blue","red")
)

# 9th plot
plot(maf_loci9, response, pch=16, col='red', cex=1.2, main='Nineth plot')                        
abline(lm(response ~ maf_loci9), col='blue')
c1 <- round(cor(maf_loci9, response, method = "pearson"), 3)
legend(0.009, 25, legend=c(c1), 
       fill = c("blue","red")
)
```

```{r}
layout_matrix <- matrix(c(1, 2, 3, 4, 5, 6, 7, 8, 9), ncol = 3, nrow = 3)  # Define position matrix
layout(layout_matrix, widths = 1:1, heights = 2:1) 
plot(1:10, main = "Plot No. 1")                           # One plot for each layout position
plot(1:10, main = "Plot No. 2")
plot(1:10, main = "Plot No. 3")
plot(1:10, main = "Plot No. 4")
plot(1:10, main = "Plot No. 1")                           # One plot for each layout position
plot(1:10, main = "Plot No. 2")
plot(1:10, main = "Plot No. 3")
plot(1:10, main = "Plot No. 4")
plot(1:10, main = "Plot No. 1")                           # One plot for each layout position
```

